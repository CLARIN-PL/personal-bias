{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import classification_report, r2_score\n",
    "import pickle\n",
    "\n",
    "from src.annotator_features import get_most_controversial_annotations, get_annotator_biases, get_text_entropies\n",
    "from src.train import prepare_dataloader, Classifier, predict\n",
    "from src.models import LSTMNet\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = './data/selected_texts/'\n",
    "\n",
    "texts_df = pd.read_csv(base_path + 'cawi2_selected_texts.csv', sep=',').iloc[:, 1:].copy()\n",
    "annotations_df = pd.read_csv(base_path + 'cawi2_selected_annotations.csv', sep=',')\n",
    "annotators_df = pd.read_csv(base_path + 'cawi2_selected_annotators.csv', sep=',')\n",
    "folds_df = pd.read_csv(base_path + 'annotator_folds.csv', sep=',')\n",
    "\n",
    "merged_annotations = texts_df.merge(annotations_df).merge(folds_df).dropna()\n",
    "merged_annotations = merged_annotations.loc[merged_annotations.annotator_id.isin(annotators_df.identyfikator)].copy()\n",
    "\n",
    "personal_df = merged_annotations[merged_annotations.split == 'past']\n",
    "\n",
    "emotion_columns = annotations_df.columns[2:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normlize_annotations(df, max_1=False):\n",
    "    df = df.copy()\n",
    "    \n",
    "    mins = df.loc[:, emotion_columns].values.min(axis=0)\n",
    "    df.loc[:, emotion_columns] = (df.loc[:, emotion_columns] - mins)\n",
    "\n",
    "    if max_1:\n",
    "        maxes = df.loc[:, emotion_columns].values.max(axis=0)\n",
    "        df.loc[:, emotion_columns] = df.loc[:, emotion_columns] / maxes\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import fasttext\n",
    "\n",
    "comments = texts_df.text.tolist()\n",
    "tokenizer = Tokenizer(num_words=None, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(comments)\n",
    "\n",
    "text_tokenized = tokenizer.texts_to_sequences(comments)\n",
    "text_lens = [len(t) for t in text_tokenized]\n",
    "\n",
    "text_tokenized = pad_sequences(text_tokenized, maxlen=256, dtype='int32', padding='post', truncating='post', value=0.0)\n",
    "\n",
    "ft = fasttext.load_model('../data/kgr10.plain.lower.skipgram.dim300.neg10.bin')\n",
    "\n",
    "word_embeddings = torch.empty((len(tokenizer.word_index.keys()) + 1, 300))\n",
    "for w, i in tokenizer.word_index.items():\n",
    "    word_embeddings[i] = torch.tensor(ft[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator_features = annotators_df.iloc[:, 1:].fillna('empty')\n",
    "\n",
    "onehots = []\n",
    "for col in annotator_features.columns:\n",
    "    onehot = pd.get_dummies(annotator_features[col]).values\n",
    "    onehots.append(onehot)\n",
    "    \n",
    "annotator_features_onehot = np.hstack(onehots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8853, 232)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_features_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_values_df = merged_annotations.loc[:, emotion_columns].fillna('empty')\n",
    "\n",
    "class_dims = []\n",
    "for col in annotation_values_df.columns:\n",
    "    onehot = pd.get_dummies(annotation_values_df[col]).values\n",
    "    class_dims.append(onehot.shape[1])\n",
    "\n",
    "sum(class_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset ids to enumerate from 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_id_idx_dict = texts_df.loc[:, ['text_id']].reset_index().set_index('text_id').to_dict()['index']\n",
    "annotator_id_idx_dict = annotators_df.loc[:, ['identyfikator']].reset_index().set_index('identyfikator').to_dict()['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score_from_results(test_predictions, true_labels, class_dims):\n",
    "    dims_results = {}\n",
    "    for cls_idx in range(len(class_dims)):\n",
    "        start_idx =  sum(class_dims[:cls_idx])\n",
    "        end_idx =  start_idx + class_dims[cls_idx]\n",
    "        preds = torch.argmax(test_predictions[:, start_idx:end_idx], dim=1)\n",
    "\n",
    "        dims_results[cls_idx] = classification_report(true_labels[:, cls_idx].cpu(), preds.cpu(), output_dict=True)\n",
    "\n",
    "    return dims_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_annotations.loc[merged_annotations.split == 'present'].copy()\n",
    "dev_df = merged_annotations.loc[merged_annotations.split == 'future1'].copy()\n",
    "test_df = merged_annotations.loc[merged_annotations.split == 'future2'].copy()\n",
    "\n",
    "train_df = normlize_annotations(train_df)\n",
    "dev_df = normlize_annotations(dev_df)\n",
    "test_df = normlize_annotations(test_df)\n",
    "\n",
    "for df in [train_df, dev_df, test_df]:\n",
    "    df['text_idx'] = df['text_id'].apply(lambda w_id: text_id_idx_dict[w_id])\n",
    "    df['annotator_idx'] = df['annotator_id'].apply(lambda r_id: annotator_id_idx_dict[r_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenario s1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:58: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "/home/user/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | model     | LSTMNet  | 17.3 M\n",
      "1 | train_acc | Accuracy | 0     \n",
      "2 | valid_acc | Accuracy | 0     \n",
      "---------------------------------------\n",
      "44.5 K    Trainable params\n",
      "17.2 M    Non-trainable params\n",
      "17.3 M    Total params\n",
      "/home/user/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b22955b7966428c8142d825310567e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 64 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77fbae7edc9f4ed3a077e6ad8a8ef227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/.local/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "ModelCheckpoint(monitor='valid_loss') not found in the returned metrics: ['train_loss_step']. HINT: Did you call self.log('valid_loss', tensor) in the LightningModule?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0e107db214b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mclassifer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'onehot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             test_predictions, true_labels = predict(classifer,\n\u001b[0m\u001b[1;32m     51\u001b[0m                                                     \u001b[0mpresent_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                                     \u001b[0mfuture1_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/big_one/persemo/user/notebooks/code/src/train.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, train_X, dev_X, test_X, train_y, dev_y, test_y, features, test_features, scenario, epochs)\u001b[0m\n\u001b[1;32m     43\u001b[0m     trainer = pl.Trainer(gpus=0, max_epochs=epochs, progress_bar_refresh_rate=20,\n\u001b[1;32m     44\u001b[0m                         checkpoint_callback=checkpoint_callback)\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;31m# hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# when a checkpoint was saved at the last step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_checkpoint_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshould_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mcheck_checkpoint_callback\u001b[0;34m(self, should_update, is_last)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_validation_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_early_stopping_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36mon_validation_end\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcheckpoints\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0msaved\u001b[0m \u001b[0mat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mend\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mval\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_backward_monitor_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_monitor_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# track epoch when ckpt was last checked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m_validate_monitor_key\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    515\u001b[0m                 \u001b[0;34mf\"HINT: Did you call self.log('{self.monitor}', tensor) in the LightningModule?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             )\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMisconfigurationException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m     def _get_metric_interpolated_filepath_name(\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: ModelCheckpoint(monitor='valid_loss') not found in the returned metrics: ['train_loss_step']. HINT: Did you call self.log('valid_loss', tensor) in the LightningModule?"
     ]
    }
   ],
   "source": [
    "for scenario in ['s1', 's2', 's3', 's4', 's5']:\n",
    "#for scenario in ['s0', 's1', 's2', 's3', 's4', 's5']:\n",
    "    results[scenario] = {}\n",
    "\n",
    "    print('scenario', scenario)\n",
    "    for fold_num in range(1):\n",
    "        future1_fold_num = fold_num\n",
    "        future2_fold_num = (fold_num + 1) % 10\n",
    "\n",
    "        present_X = train_df.loc[~train_df.fold.isin([future1_fold_num, future2_fold_num]), ['text_idx', 'annotator_idx']].values\n",
    "        present_y = train_df.loc[~train_df.fold.isin([future1_fold_num, future2_fold_num]), emotion_columns].values\n",
    "\n",
    "        future1_X = dev_df.loc[dev_df.fold == future1_fold_num, ['text_idx', 'annotator_idx']].values\n",
    "        future1_y = dev_df.loc[dev_df.fold == future1_fold_num, emotion_columns].values\n",
    "\n",
    "        future2_X = test_df.loc[test_df.fold == future2_fold_num, ['text_idx', 'annotator_idx']].values\n",
    "        future2_y = test_df.loc[test_df.fold == future2_fold_num, emotion_columns].values\n",
    "        \n",
    "        # biases for train datset\n",
    "        filtered_personal_df = personal_df[~personal_df.fold.isin([future1_fold_num, future2_fold_num])]\n",
    "        filtered_annotations = get_most_controversial_annotations(filtered_personal_df, emotion_columns, None)\n",
    "        annotator_biases = get_annotator_biases(filtered_annotations, emotion_columns)\n",
    "        annotator_biases = (pd.DataFrame(annotators_df.loc[:, 'identyfikator'])\n",
    "                            .merge(annotator_biases, right_on='annotator_id', left_on='identyfikator', how='left')\n",
    "                            .fillna(0))\n",
    "        \n",
    "        # biases for test dataset\n",
    "        filtered_annotations = get_most_controversial_annotations(personal_df, emotion_columns, None)\n",
    "        test_annotator_biases = get_annotator_biases(filtered_annotations, emotion_columns)\n",
    "        test_annotator_biases = (pd.DataFrame(annotators_df.loc[:, 'identyfikator'])\n",
    "                            .merge(test_annotator_biases, right_on='annotator_id', left_on='identyfikator', how='left')\n",
    "                            .fillna(0))\n",
    "        \n",
    "        features = text_tokenized, annotator_features_onehot, annotator_biases.iloc[:, 1:].values\n",
    "        test_features = text_tokenized, annotator_features_onehot, test_annotator_biases.iloc[:, 1:].values\n",
    "        \n",
    "        if scenario == 's0':\n",
    "            s0_predictions = np.tile(present_y.mean(axis=0).round(), (future2_y.shape[0], 1))\n",
    "            results[scenario][fold_num] = ([classification_report(future2_y[:, i], s0_predictions[:, i], output_dict=True) \n",
    "                                            for i in range(future2_y.shape[1])])\n",
    "        else:\n",
    "            dataloader = prepare_dataloader(present_X, present_y, features, scenario)\n",
    "            text_feature_num = next(iter(dataloader))[0].size(-1)\n",
    "            additional_feature_num = next(iter(dataloader))[1].size(-1)\n",
    "\n",
    "            classes_num = sum(class_dims)\n",
    "            model = LSTMNet(classes_num, text_feature_num, additional_feature_num, word_embeddings).to(device)\n",
    "            classifer = Classifier(model=model, output_type='onehot', output_dims=class_dims).to(device)\n",
    "\n",
    "            test_predictions, true_labels = predict(classifer,\n",
    "                                                    present_X, \n",
    "                                                    future1_X, \n",
    "                                                    future2_X, \n",
    "                                                    present_y, \n",
    "                                                    future1_y, \n",
    "                                                    future2_y, \n",
    "                                                    features,\n",
    "                                                    test_features,\n",
    "                                                    scenario,\n",
    "                                                    epochs=2)\n",
    "            \n",
    "            results[scenario][fold_num] = get_f1_score_from_results(test_predictions, true_labels, class_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {k: np.mean([[results[k][f_num][c_idx]['macro avg']['f1-score'] for f_num in results[k].keys()] for c_idx in range(10)], axis=1) for k in results.keys()}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict)\n",
    "results_df.index = emotion_columns\n",
    "print(f'{MODEL_NAME} + OneHot classification, R^2 score')\n",
    "\n",
    "results_df.columns = ['s0 (AVG)', 's1 (TXT)', 's2 (TXT+DEM)', 's3 (PEB)', 's4 (TXT+PEB)', 's5 (TXT+PEB+DEM)']\n",
    "results_df.index = ['anticipation',\n",
    "                   'arousal',\n",
    "                   'joy',\n",
    "                   'sadness',\n",
    "                   'fear',\n",
    "                   'disgust',\n",
    "                    'surprise',\n",
    "                    'trust',\n",
    "                    'polarity',\n",
    "                    'anger',\n",
    "                   ]\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mean = pd.DataFrame(results_df.values.mean(axis=0)[None,:])\n",
    "results_df_mean.columns = results_df.columns\n",
    "results_df_mean.index = [f'{MODEL_NAME} F1 score']\n",
    "results_df_mean = results_df_mean * 100\n",
    "results_df_mean = results_df_mean.round(2)\n",
    "results_df_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r2_score_from_results(test_predictions, true_labels):\n",
    "    true_labels = true_labels.cpu().numpy()#[:, i]\n",
    "    test_predictions = test_predictions.cpu().numpy()#[:, i]\n",
    "    \n",
    "    losses = [r2_score(true_labels[:, i], test_predictions[:, i]) for i in range(test_predictions.shape[1])]\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = merged_annotations.loc[merged_annotations.split == 'present'].copy()\n",
    "dev_df = merged_annotations.loc[merged_annotations.split == 'future1'].copy()\n",
    "test_df = merged_annotations.loc[merged_annotations.split == 'future2'].copy()\n",
    "\n",
    "train_df = normlize_annotations(train_df, True)\n",
    "dev_df = normlize_annotations(dev_df, True)\n",
    "test_df = normlize_annotations(test_df, True)\n",
    "\n",
    "for df in [train_df, dev_df, test_df]:\n",
    "    df['text_idx'] = df['text_id'].apply(lambda w_id: text_id_idx_dict[w_id])\n",
    "    df['annotator_idx'] = df['annotator_id'].apply(lambda r_id: annotator_id_idx_dict[r_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scenario in ['s0', 's1', 's2', 's3', 's4', 's5']:\n",
    "    results[scenario] = {}\n",
    "\n",
    "    print('scenario', scenario)\n",
    "    for fold_num in range(10):\n",
    "        future1_fold_num = fold_num\n",
    "        future2_fold_num = (fold_num + 1) % 10\n",
    "\n",
    "        present_X = train_df.loc[~train_df.fold.isin([future1_fold_num, future2_fold_num]), ['text_idx', 'annotator_idx']].values\n",
    "        present_y = train_df.loc[~train_df.fold.isin([future1_fold_num, future2_fold_num]), emotion_columns].values\n",
    "\n",
    "        future1_X = dev_df.loc[dev_df.fold == future1_fold_num, ['text_idx', 'annotator_idx']].values\n",
    "        future1_y = dev_df.loc[dev_df.fold == future1_fold_num, emotion_columns].values\n",
    "\n",
    "        future2_X = test_df.loc[test_df.fold == future2_fold_num, ['text_idx', 'annotator_idx']].values\n",
    "        future2_y = test_df.loc[test_df.fold == future2_fold_num, emotion_columns].values\n",
    "        \n",
    "        filtered_personal_df = personal_df[~personal_df.fold.isin([future1_fold_num, future2_fold_num])]\n",
    "        filtered_annotations = get_most_controversial_annotations(filtered_personal_df, emotion_columns, None)\n",
    "        annotator_biases = get_annotator_biases(filtered_annotations, emotion_columns)\n",
    "        annotator_biases = (pd.DataFrame(annotators_df.loc[:, 'identyfikator'])\n",
    "                            .merge(annotator_biases, right_on='annotator_id', left_on='identyfikator', how='left')\n",
    "                            .fillna(0))\n",
    "        \n",
    "        filtered_annotations = get_most_controversial_annotations(personal_df, emotion_columns, None)\n",
    "        test_annotator_biases = get_annotator_biases(filtered_annotations, emotion_columns)\n",
    "        test_annotator_biases = (pd.DataFrame(annotators_df.loc[:, 'identyfikator'])\n",
    "                            .merge(test_annotator_biases, right_on='annotator_id', left_on='identyfikator', how='left')\n",
    "                            .fillna(0))\n",
    "        \n",
    "        features = text_tokenized, annotator_features_onehot, annotator_biases.iloc[:, 1:].values\n",
    "        test_features = text_tokenized, annotator_features_onehot, test_annotator_biases.iloc[:, 1:].values\n",
    "        \n",
    "        if scenario == 's0':\n",
    "            s0_predictions = torch.tensor(np.tile(present_y.mean(axis=0), (future2_y.shape[0], 1)))\n",
    "            results[scenario][fold_num] = np.array([r2_score(future2_y[:, i], s0_predictions[:, i]) \n",
    "                                                    for i in range(future2_y.shape[1])])\n",
    "            \n",
    "        else:\n",
    "            dataloader = prepare_dataloader(present_X, present_y, features, scenario)\n",
    "            text_feature_num = next(iter(dataloader))[0].size(-1)\n",
    "            additional_feature_num = next(iter(dataloader))[1].size(-1)\n",
    "\n",
    "            classes_num = 10\n",
    "            model = Net(classes_num, text_feature_num, additional_feature_num).to(device)\n",
    "            classifer = Classifier(model=model, output_type='mse', output_dims=None).to(device)\n",
    "\n",
    "            test_predictions, true_labels = predict(classifer,\n",
    "                                                    present_X, \n",
    "                                                    future1_X, \n",
    "                                                    future2_X, \n",
    "                                                    present_y, \n",
    "                                                    future1_y, \n",
    "                                                    future2_y, \n",
    "                                                    features,\n",
    "                                                    test_features,\n",
    "                                                    scenario,\n",
    "                                                    epochs=15)\n",
    "            \n",
    "            results[scenario][fold_num] = get_r2_score_from_results(test_predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {k: np.mean([np.array(results[k][i]) for i in results[k].keys()], axis=0) for k in results.keys()}\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict)\n",
    "results_df.index = emotion_columns\n",
    "print(f'{MODEL_NAME} + Regression, R^2 score')\n",
    "\n",
    "results_df.columns = ['s0 (AVG)', 's1 (TXT)',  's2 (TXT+DEM)', 's3 (PEB)', 's4 (TXT+PEB)', 's5 (TXT+PEB+DEM)']\n",
    "results_df.index = ['anticipation',\n",
    "                   'arousal',\n",
    "                   'joy',\n",
    "                   'sadness',\n",
    "                   'fear',\n",
    "                   'disgust',\n",
    "                    'surprise',\n",
    "                    'trust',\n",
    "                    'polarity',\n",
    "                    'anger',\n",
    "                   ]\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_mean = pd.DataFrame(results_df.values.mean(axis=0)[None,:])\n",
    "results_df_mean.columns = results_df.columns\n",
    "results_df_mean.index = [f'{MODEL_NAME} R squared']\n",
    "results_df_mean = results_df_mean * 100\n",
    "results_df_mean.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
